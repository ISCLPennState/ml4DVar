{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py, os, sys\n",
    "from netCDF4 import Dataset\n",
    "import numpy as np\n",
    "import torch\n",
    "from scipy.interpolate import interpn\n",
    "from torch.autograd import Function\n",
    "from scipy.sparse import coo_matrix, csr_matrix\n",
    "from scipy.interpolate import interpn\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_H(lat_idxs, lon_idxs, lat_delta, lon_delta, lat_grid, lon_grid):\n",
    "    # lat_idxs, lon_idxs -> grid_space of obs\n",
    "    # lat_delta, lon_delta -> grid_space difference\n",
    "    # lat_grid = np.arange(-90,90,128)\n",
    "    # lon_grid = np.arange(0,360,256)\n",
    "\n",
    "    '''\n",
    "    Computes the model grid interpolated onto the observation grid and returns result and the observation operator\n",
    "    :param lat_idxs:\n",
    "    :param lon_idxs:\n",
    "    :param lat_delta:\n",
    "    :param lon_delta:\n",
    "    :return:\n",
    "    '''\n",
    "    # TODO double check this is correct\n",
    "    lat_grid_delta = np.append(lat_grid[1:] - lat_grid[:-1], 90 - lat_grid[-1] + lat_grid[0] + 90) # [1.40625]*128\n",
    "    lon_grid_delta = np.append(lon_grid[1:] - lon_grid[:-1], 360 - lon_grid[-1] + lon_grid[0]) # [1.40625]*256\n",
    "    H = np.zeros((lat_idxs.size, 4, 2)) # (num_obs,4,2)\n",
    "    H[:, 0, 0] = np.ravel_multi_index((lat_idxs, lon_idxs), (lat_grid.size, lon_grid.size)) # finds index of lat-lon pair in flattened (128,256) vector\n",
    "    H[:, 1, 0] = np.ravel_multi_index(((lat_idxs + 1) % lat_grid.size, lon_idxs), (lat_grid.size, lon_grid.size))\n",
    "    H[:, 2, 0] = np.ravel_multi_index((lat_idxs, (lon_idxs + 1) % lon_grid.size), (lat_grid.size, lon_grid.size))\n",
    "    H[:, 3, 0] = np.ravel_multi_index(((lat_idxs + 1) % lat_grid.size, (lon_idxs + 1) % lon_grid.size),\n",
    "                                      (lat_grid.size, lon_grid.size))\n",
    "    denominator = 1. / (lat_grid_delta[lat_idxs] * lon_grid_delta[lon_idxs]) # \n",
    "    H[:, 0, 1] = denominator * (lat_grid_delta[lat_idxs] - lat_delta) * (lon_grid_delta[lon_idxs] - lon_delta) # H holds delta information for iterpolation\n",
    "    H[:, 1, 1] = denominator * (lat_delta) * (lon_grid_delta[lon_idxs] - lon_delta)\n",
    "    H[:, 2, 1] = denominator * (lat_grid_delta[lat_idxs] - lat_delta) * (lon_delta)\n",
    "    H[:, 3, 1] = denominator * lat_delta * lon_delta\n",
    "    return H.reshape(-1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using lats : [-89.296875 -87.890625 -86.484375 -85.078125 -83.671875 -82.265625\n",
      " -80.859375 -79.453125 -78.046875 -76.640625 -75.234375 -73.828125\n",
      " -72.421875 -71.015625 -69.609375 -68.203125 -66.796875 -65.390625\n",
      " -63.984375 -62.578125 -61.171875 -59.765625 -58.359375 -56.953125\n",
      " -55.546875 -54.140625 -52.734375 -51.328125 -49.921875 -48.515625\n",
      " -47.109375 -45.703125 -44.296875 -42.890625 -41.484375 -40.078125\n",
      " -38.671875 -37.265625 -35.859375 -34.453125 -33.046875 -31.640625\n",
      " -30.234375 -28.828125 -27.421875 -26.015625 -24.609375 -23.203125\n",
      " -21.796875 -20.390625 -18.984375 -17.578125 -16.171875 -14.765625\n",
      " -13.359375 -11.953125 -10.546875  -9.140625  -7.734375  -6.328125\n",
      "  -4.921875  -3.515625  -2.109375  -0.703125   0.703125   2.109375\n",
      "   3.515625   4.921875   6.328125   7.734375   9.140625  10.546875\n",
      "  11.953125  13.359375  14.765625  16.171875  17.578125  18.984375\n",
      "  20.390625  21.796875  23.203125  24.609375  26.015625  27.421875\n",
      "  28.828125  30.234375  31.640625  33.046875  34.453125  35.859375\n",
      "  37.265625  38.671875  40.078125  41.484375  42.890625  44.296875\n",
      "  45.703125  47.109375  48.515625  49.921875  51.328125  52.734375\n",
      "  54.140625  55.546875  56.953125  58.359375  59.765625  61.171875\n",
      "  62.578125  63.984375  65.390625  66.796875  68.203125  69.609375\n",
      "  71.015625  72.421875  73.828125  75.234375  76.640625  78.046875\n",
      "  79.453125  80.859375  82.265625  83.671875  85.078125  86.484375\n",
      "  87.890625  89.296875]\n",
      "Using longs : [  0.        1.40625   2.8125    4.21875   5.625     7.03125   8.4375\n",
      "   9.84375  11.25     12.65625  14.0625   15.46875  16.875    18.28125\n",
      "  19.6875   21.09375  22.5      23.90625  25.3125   26.71875  28.125\n",
      "  29.53125  30.9375   32.34375  33.75     35.15625  36.5625   37.96875\n",
      "  39.375    40.78125  42.1875   43.59375  45.       46.40625  47.8125\n",
      "  49.21875  50.625    52.03125  53.4375   54.84375  56.25     57.65625\n",
      "  59.0625   60.46875  61.875    63.28125  64.6875   66.09375  67.5\n",
      "  68.90625  70.3125   71.71875  73.125    74.53125  75.9375   77.34375\n",
      "  78.75     80.15625  81.5625   82.96875  84.375    85.78125  87.1875\n",
      "  88.59375  90.       91.40625  92.8125   94.21875  95.625    97.03125\n",
      "  98.4375   99.84375 101.25    102.65625 104.0625  105.46875 106.875\n",
      " 108.28125 109.6875  111.09375 112.5     113.90625 115.3125  116.71875\n",
      " 118.125   119.53125 120.9375  122.34375 123.75    125.15625 126.5625\n",
      " 127.96875 129.375   130.78125 132.1875  133.59375 135.      136.40625\n",
      " 137.8125  139.21875 140.625   142.03125 143.4375  144.84375 146.25\n",
      " 147.65625 149.0625  150.46875 151.875   153.28125 154.6875  156.09375\n",
      " 157.5     158.90625 160.3125  161.71875 163.125   164.53125 165.9375\n",
      " 167.34375 168.75    170.15625 171.5625  172.96875 174.375   175.78125\n",
      " 177.1875  178.59375 180.      181.40625 182.8125  184.21875 185.625\n",
      " 187.03125 188.4375  189.84375 191.25    192.65625 194.0625  195.46875\n",
      " 196.875   198.28125 199.6875  201.09375 202.5     203.90625 205.3125\n",
      " 206.71875 208.125   209.53125 210.9375  212.34375 213.75    215.15625\n",
      " 216.5625  217.96875 219.375   220.78125 222.1875  223.59375 225.\n",
      " 226.40625 227.8125  229.21875 230.625   232.03125 233.4375  234.84375\n",
      " 236.25    237.65625 239.0625  240.46875 241.875   243.28125 244.6875\n",
      " 246.09375 247.5     248.90625 250.3125  251.71875 253.125   254.53125\n",
      " 255.9375  257.34375 258.75    260.15625 261.5625  262.96875 264.375\n",
      " 265.78125 267.1875  268.59375 270.      271.40625 272.8125  274.21875\n",
      " 275.625   277.03125 278.4375  279.84375 281.25    282.65625 284.0625\n",
      " 285.46875 286.875   288.28125 289.6875  291.09375 292.5     293.90625\n",
      " 295.3125  296.71875 298.125   299.53125 300.9375  302.34375 303.75\n",
      " 305.15625 306.5625  307.96875 309.375   310.78125 312.1875  313.59375\n",
      " 315.      316.40625 317.8125  319.21875 320.625   322.03125 323.4375\n",
      " 324.84375 326.25    327.65625 329.0625  330.46875 331.875   333.28125\n",
      " 334.6875  336.09375 337.5     338.90625 340.3125  341.71875 343.125\n",
      " 344.53125 345.9375  347.34375 348.75    350.15625 351.5625  352.96875\n",
      " 354.375   355.78125 357.1875  358.59375]\n"
     ]
    }
   ],
   "source": [
    "lat = np.load('/eagle/MDClimSim/troyarcomano/1.40625deg_npz_40shards/lat.npy')\n",
    "long = np.load('/eagle/MDClimSim/troyarcomano/1.40625deg_npz_40shards/lon.npy')\n",
    "print('Using lats :',lat)\n",
    "print('Using longs :',long)\n",
    "\n",
    "def find_index_delta(x, y):\n",
    "    # x (lat) (-90,90)\n",
    "    # y (lon) (0,360)\n",
    "\n",
    "    xi = np.searchsorted(lat, x, side='left') - 1 # lat -> x_idx\n",
    "    delta_x = x - lat[xi]\n",
    "    x_remove = xi == -1\n",
    "    if np.any(x_remove):\n",
    "        delta_x[xi == -1] = 180 + x[xi == -1] - lat[-1]\n",
    "        xi[xi == -1] = len(lat) - 1\n",
    "    yi = np.searchsorted(long, y, side='left') - 1 # lon -> y_idx\n",
    "    delta_y = y - long[yi]\n",
    "    y_remove = yi == -1\n",
    "    if np.any(y_remove):\n",
    "        delta_y[yi == -1] = 360 + y[yi == -1] - long[-1]\n",
    "        yi[yi == -1] = len(long) - 1\n",
    "    return xi, yi, delta_x, delta_y, x_remove, y_remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using means : <numpy.lib.npyio.NpzFile object at 0x7f6ad06c2b50>\n",
      "\n",
      "Old means : <numpy.lib.npyio.NpzFile object at 0x7f6ad05e57f0>\n",
      "\n",
      "Using stds : <numpy.lib.npyio.NpzFile object at 0x7f6b74a849d0>\n",
      "\n",
      "Old stds : <numpy.lib.npyio.NpzFile object at 0x7f6ad06c2f10>\n"
     ]
    }
   ],
   "source": [
    "old_means = np.load('/eagle/MDClimSim/troyarcomano/1.40625deg_npz_40shards/normalize_mean.npz')\n",
    "old_stds = np.load('/eagle/MDClimSim/troyarcomano/1.40625deg_npz_40shards/normalize_std.npz')\n",
    "\n",
    "# Use new means and stds\n",
    "means = np.load('/eagle/MDClimSim/tungnd/data/wb2/1.40625deg_from_full_res_1_step_6hr_h5df/normalize_mean.npz')\n",
    "stds = np.load('/eagle/MDClimSim/tungnd/data/wb2/1.40625deg_from_full_res_1_step_6hr_h5df/normalize_std.npz')\n",
    "print('\\nUsing means :',means)\n",
    "print('\\nOld means :',old_means)\n",
    "print('\\nUsing stds :',stds)\n",
    "print('\\nOld stds :',old_stds)\n",
    "\n",
    "dir = '/eagle/MDClimSim/awikner'\n",
    "troy_dir = '/eagle/MDClimSim/troyarcomano/ml4dvar_climax_v2/'\n",
    "matt_dir = '/eagle/MDClimSim/mjp5595/ml4dvar/obs/'\n",
    "\n",
    "full_obs_file = 'irga_2014_2015_2020_all.hdf5'\n",
    "msl_obs_file = 'irga_2014_2015_2020_msl_all.hdf5'\n",
    "obs_file = 'igra_141520_stormer_obs_standardized_360_3.hdf5'\n",
    "obs_file_raw = 'igra_141520_stormer_obs_standardized_360_3_raw.hdf5'\n",
    "\n",
    "#if os.path.exists(os.path.join(matt_dir, obs_file)):\n",
    "#    os.remove(os.path.join(matt_dir, obs_file))\n",
    "f = h5py.File(os.path.join(dir, full_obs_file), 'r')\n",
    "f_msl = h5py.File(os.path.join(dir, msl_obs_file), 'r')\n",
    "#f_obs = h5py.File(os.path.join(matt_dir, obs_file), 'a')\n",
    "#f_obs_raw = h5py.File(os.path.join(matt_dir, obs_file_raw), 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOUNDING_TO_STORMER_pl = {'gph':'geopotential','q':'specific_humidity','temp':'temperature','uwind':'u_component_of_wind','vwind':'v_component_of_wind'}\n",
    "SOUNDING_TO_STORMER_sl = {'surface_press':'mean_sea_level_pressure','surface_uwind':'10m_u_component_of_wind', 'surface_vwind':'10m_v_component_of_wind', 'surface_temp':'2m_temperature'}\n",
    "\n",
    "modeled_vars = ['gph', 'uwind', 'vwind', 'temp', 'q']\n",
    "mean_std_names = ['geopotential', 'u_component_of_wind', 'v_component_of_wind', 'temperature', 'specific_humidity']\n",
    "\n",
    "modeled_surface_vars = ['surface_press', 'surface_uwind', 'surface_vwind', 'surface_temp']\n",
    "\n",
    "pred_plevels = np.array([1000, 925, 850, 700, 600, 500, 400, 300, 250, 200, 150, 100, 50], dtype='f8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_keys() : <KeysViewHDF5 ['dpdp', 'gph', 'q', 'rh', 'surface_dpdp', 'surface_press', 'surface_q', 'surface_rh', 'surface_temp', 'surface_uwind', 'surface_vwind', 'temp', 'uwind', 'vwind']>\n",
      "f_msk_keys() : <KeysViewHDF5 ['surface_press']>\n"
     ]
    }
   ],
   "source": [
    "print('f_keys() :',f['2014/01/01/00/'].keys())\n",
    "print('f_msk_keys() :',f_msl['2014/01/01/00/'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sp.shape, min, mean, max : (600,) 330.5559196292297 943.2858966081803 1142.298573570242\n",
      "sp_msl.shape, min, mean, max : (592,) 973.8298933373367 1015.6057182564184 1068.442446946132\n"
     ]
    }
   ],
   "source": [
    "sp = f['2014/01/01/12/surface_press'][:,3]\n",
    "sp_msl = f_msl['2014/01/01/12/surface_press'][:,3]\n",
    "\n",
    "print('sp.shape, min, mean, max :',sp.shape,np.min(sp),np.mean(sp),np.max(sp))\n",
    "print('sp_msl.shape, min, mean, max :',sp_msl.shape,np.min(sp_msl),np.mean(sp_msl),np.max(sp_msl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sp_msl.shape, min, mean, max : (592,) 973.8298933373367 1015.6057182564184 1068.442446946132\n"
     ]
    }
   ],
   "source": [
    "sp_msl = f_msl['2014/01/01/12/surface_press'][:,3]\n",
    "print('sp_msl.shape, min, mean, max :',sp_msl.shape,np.min(sp_msl),np.mean(sp_msl),np.max(sp_msl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in list(f.keys()):\n",
    "    #yr_grp = f_obs.create_group(year)\n",
    "    for month in list(f[year].keys()):\n",
    "        #mth_grp = f_obs[year].create_group(month)\n",
    "        for day in list(f[year + '/' + month].keys()):\n",
    "            #day_grp = f_obs[year + '/' + month].create_group(day)\n",
    "            for hour in list(f[year + '/' + month + '/' + day].keys()):\n",
    "                print(year + '/' + month + '/' + day + '/' + hour)\n",
    "                #hr_group = f_obs[year + '/' + month + '/' + day].create_group(hour)\n",
    "                for var_idx, var in enumerate(modeled_surface_vars):\n",
    "                    #print('var_idx, var (0):',var_idx, var)\n",
    "\n",
    "                    if var == 'surface_press':\n",
    "                        try:\n",
    "                            obs_data = f_msl[year + '/' + month + '/' + day + '/' + hour + '/' + var][:]\n",
    "                        except:\n",
    "                            continue\n",
    "                    else:\n",
    "                        try:\n",
    "                            obs_data = f[year + '/' + month + '/' + day + '/' + hour + '/' + var][:]\n",
    "                        except:\n",
    "                            continue\n",
    "                    obs_data = f[year + '/' + month + '/' + day + '/' + hour + '/' + var][:] # (n_obs, 4) -> (605, 4)\n",
    "                    var_mean = means[f'{SOUNDING_TO_STORMER_sl[var]}'][0]\n",
    "                    var_std = stds[f'{SOUNDING_TO_STORMER_sl[var]}'][0]\n",
    "\n",
    "                    #try:\n",
    "                    #    old_var_mean = old_means['%s' % (surface_vars_dict[var])][0]\n",
    "                    #    old_var_std = old_stds['%s' % (surface_vars_dict[var])][0]\n",
    "                    #    print('var, old_var_mean, new_var_mean :',var, old_var_mean,var_mean)\n",
    "                    #    print('var, old_var_std, new_var_std :',var, old_var_std,var_std)\n",
    "                    #except:\n",
    "                    #    print('var, new_var_mean :',var, var_mean)\n",
    "                    #    print('var, new_var_std :',var, var_std)\n",
    "\n",
    "                    plevel_data = obs_data[:,[0,1,3]]\n",
    "                    #plevel_data = plevel_data[np.lexsort((plevel_data[:, 1], plevel_data[:, 0]))]\n",
    "                    #lat_obs = plevel_data[:, 0]\n",
    "                    #long_obs = plevel_data[:, 1]\n",
    "                    long_obs = (plevel_data[:, 1] + 360) % 360\n",
    "                    plevel_data[:,1] = long_obs\n",
    "                    plevel_data = plevel_data[np.lexsort((plevel_data[:, 1], plevel_data[:, 0]))]\n",
    "                    lat_obs = plevel_data[:, 0]\n",
    "                    long_obs = plevel_data[:,1]\n",
    "\n",
    "                    #print('\\tlong_obs (min/max):',min(long_obs),max(long_obs))\n",
    "                    xi, yi, delta_x, delta_y, x_remove, y_remove = find_index_delta(lat_obs, long_obs)\n",
    "                    red_idxs = (np.logical_not(x_remove)) & (np.logical_not(y_remove)) & \\\n",
    "                                (xi != len(lat) - 1) & (yi != len(long) - 1)\n",
    "                    plevel_data = plevel_data[red_idxs] # (n_obs, 3) -> (604,3)\n",
    "                    delta_x = delta_x[red_idxs]\n",
    "                    delta_y = delta_y[red_idxs]\n",
    "                    xi_red = xi[red_idxs]\n",
    "                    yi_red = yi[red_idxs]\n",
    "                    plevel_dataset = f_obs[year + '/' + month + '/' + day + '/' + hour].create_dataset(\n",
    "                        '%s' % (f'{SOUNDING_TO_STORMER_sl[var]}'), data=plevel_data, dtype = 'f8'\n",
    "                    )\n",
    "                    plevel_dataset[:, :2] = plevel_data[:, :2]\n",
    "\n",
    "                    #############################################################################################\n",
    "                    #############################################################################################\n",
    "                    # TODO should this be x100 here? Need to check final values\n",
    "                    if var == 'surface_press':\n",
    "                        plevel_dataset[:, 2] = (plevel_data[:, 2]*100 - var_mean)/var_std\n",
    "                    elif var == 'surface_temp':\n",
    "                        plevel_dataset[:, 2] = (plevel_data[:, 2] + 273.15 - var_mean) / var_std\n",
    "                    else:\n",
    "                        plevel_dataset[:, 2] = (plevel_data[:, 2] - var_mean) / var_std\n",
    "                    plevel_dataset.attrs['mean'] = var_mean\n",
    "                    plevel_dataset.attrs['std'] = var_std\n",
    "\n",
    "                    H = compute_H(xi_red, yi_red, delta_x, delta_y, lat, long)\n",
    "                    H_var_data = f_obs[year + '/' + month + '/' + day + '/' + hour].create_dataset(\n",
    "                        '%s_H' % (f'{SOUNDING_TO_STORMER_sl[var]}'), H.shape, dtype = 'f8'\n",
    "                    )\n",
    "                    H_var_data[:] = H\n",
    "                    #############################################################################################\n",
    "                    #############################################################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climaX",
   "language": "python",
   "name": "climax"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
